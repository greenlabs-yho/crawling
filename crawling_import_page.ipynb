{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panjiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HS 12 - Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit, industrial or medicinal plants; straw and fodder'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://panjiva.com/Sesaco-Corporation/87477611'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
    "}\n",
    "page_response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "\n",
    "\n",
    "h1 = soup.find('h1')\n",
    "print(h1.text.strip())\n",
    "for span in soup.find_all('span', class_=\"profileHeader\"):\n",
    "    if span.find(\"img\"):\n",
    "        print(span.text.strip())\n",
    "soup.find('a', class_=\"itemHtsCode\").text.strip().replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {}\n",
    "h1 = soup.find('h1')\n",
    "if h1:\n",
    "    item[\"name\"] = h1.text.strip()\n",
    "for span in soup.find_all('span', class_=\"profileHeader\"):\n",
    "    if span.find(\"img\"):\n",
    "        item[\"country\"] = span.text.strip()\n",
    "        break\n",
    "item[\"product\"] = soup.find('a', class_=\"itemHtsCode\").text.strip().replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sesaco Corporation',\n",
       " 'country': 'United States',\n",
       " 'product': 'HS 12 - Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit, industrial or medicinal plants; straw and fodder'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HS 12 -'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# The text from which to extract \"HS 12\"\n",
    "text = \"HS 12 - Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit, industrial or medicinal plants; straw and fodder\"\n",
    "# Adjusting the pattern to ensure \"HS\" is at the start and the text ends with \"-\"\n",
    "pattern_tight = r'^HS \\d+ -'\n",
    "\n",
    "# Search for the adjusted pattern in the text\n",
    "match_tight = re.search(pattern_tight, text)\n",
    "\n",
    "# Extract the matched pattern\n",
    "extracted_text_tight = match_tight.group() if match_tight else None\n",
    "extracted_text_tight\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImportGenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.importgenius.co.kr/importers/gs-global-usa-inc'\n",
    "#url = \"https://www.importgenius.com/suppliers/reitz-schweiz-ventilator-ag\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \n",
    "}\n",
    "page_response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "page_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gs Global Usa Inc.\n",
      "{'name': 'GS GLOBAL USA INC', 'address': '17785 CENTER COURT DR., SUITE 260 CERRITOS, CA 90703 UNITED STATES'}\n",
      "HOT ROLLEDPLATE 66.668 MT HOT ROLLED STEEL PLATES\n"
     ]
    }
   ],
   "source": [
    "h1 = soup.find(\"h1\", class_=\"company-name\")\n",
    "name = h1.text.strip()\n",
    "print(name)\n",
    "comp_wrapper = soup.find(\"div\", class_=\"company-card-wrapper\")\n",
    "# 모든 회사 카드를 찾습니다.\n",
    "company_cards = comp_wrapper.find_all('div', class_='company-card')\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "companies_info = []\n",
    "\n",
    "# 각 회사 카드에서 회사명과 주소를 추출\n",
    "for card in company_cards:\n",
    "    if \"notify\" not in card.find('div', class_='company-type').get_text(strip=True).lower():\n",
    "        comp_info = {}\n",
    "        if card.find('div', class_='company-name'):\n",
    "            comp_info[\"name\"] = card.find('div', class_='company-name').get_text(strip=True)\n",
    "        if card.find('li', class_='company-location'):\n",
    "            comp_info[\"address\"] = card.find('li', class_='company-location').get_text(strip=True)\n",
    "        \n",
    "        if comp_info:\n",
    "            companies_info.append(comp_info)\n",
    "\n",
    "from scraping_packers_homepage.tools.cleanser import cleansing_comp_name\n",
    "cleansed_name = cleansing_comp_name(name)\n",
    "# 추출된 정보 출력\n",
    "for company in companies_info:\n",
    "    cleansed_item = cleansing_comp_name(company[\"name\"])\n",
    "    if cleansed_name == cleansed_item:\n",
    "        print(company)\n",
    "\n",
    "desc_div = soup.find(\"div\", class_=\"p-4\", attrs={\"itemprop\": \"partOfOrder\"})\n",
    "td_list = desc_div.find_all(\"td\", attrs={\"colspan\": \"3\"})\n",
    "if td_list and len(td_list) > 1 and td_list[1].find('span'):\n",
    "    print(td_list[1].find('span').text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExportGenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gsi Group Llc', 'Importer in Usa ', ' Bill of Lading Data of Gsi']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "title = \"Gsi Group Llc is an Importer in Usa | Bill of Lading Data of Gsi\"\n",
    "re.split(',|\\||-|/| is an ', title) # , | - / 기준으로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.exportgenius.in/gsi-group-llc-importer-in-usa'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \n",
    "}\n",
    "page_response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "page_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSI GROUP LLC\n",
      "Usa\n",
      "843629\n",
      "\"unit for poultry equipment hs code 843629 shipment terms: exw please, deliver to olivera foods 952\n",
      "west bowman road 95321 french camp, ca\"\n"
     ]
    }
   ],
   "source": [
    "div = soup.find(\"div\", class_=\"prbbr\")\n",
    "print(div.find('h1').getText(strip=True))\n",
    "print(soup.find('p').text.split()[-1])\n",
    "\n",
    "table = soup.find('table', class_=\"table_prod table-bordered_prod table-striped_prod\")\n",
    "td_title = table.find(\"td\", text=\"HS Code\")\n",
    "\n",
    "if td_title and td_title.findParent().find_all(\"td\"):\n",
    "    print(td_title.findParent().find_all(\"td\")[1].text.strip())\n",
    "\n",
    "td_title = table.find(\"td\", text=\"Product Description\")\n",
    "\n",
    "if td_title and td_title.findParent().find_all(\"td\"):\n",
    "    print(td_title.findParent().find_all(\"td\")[1].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.seair.co.in/peru-exporter/transporte-aereo-den-sac.aspx'\n",
    "url = 'https://www.seair.co.in/us-importers/cobot-corp.aspx'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \n",
    "}\n",
    "page_response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "page_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSPORTE AEREO DEN SAC\n",
      "US\n",
      "BOX S.T.C. USED AIRCRAFT ENGINE.\n"
     ]
    }
   ],
   "source": [
    "# https://www.seair.co.in/peru-exporter/transporte-aereo-den-sac.aspx\n",
    "ul = soup.find('ul', class_=\"inner_breadcrumb\")\n",
    "print(ul.find_all('li')[2].text.strip())\n",
    "print(ul.find_all('li')[1].text.strip().replace(\" Exporter\", \"\"))\n",
    "\n",
    "sample_div = soup.find('div', class_=\"table-responsive table_side\")\n",
    "th_list = sample_div.find_all(\"th\")\n",
    "for th in th_list:\n",
    "    if th.getText(strip=True) == \"Details\":\n",
    "        print(th.findParent().find(\"td\").getText(strip=True))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artim international\n",
      "Ecuador\n",
      "{'SAMPLES OF CERAMICS', 'SAMPLES OF MIRRORS BALLS-LIGHTS-LED-PEDICURE ACCESSORIES', 'SAMPLE OF CUP-SPATULA-TIME CONTROLLER-SPOON', 'BRUSH-CLIPS-CAPA SAMPLE'}\n"
     ]
    }
   ],
   "source": [
    "# https://www.seair.co.in/artim-international-importers-in-ecuador\n",
    "print(soup.find('h1').text.strip())\n",
    "print(soup.find('h2', class_=\"h6 mt-3 mb-3\").getText(strip=True).replace(\"Importer in \", ''))\n",
    "\n",
    "product_list = set()\n",
    "for prod in soup.find_all('td', attrs={\"data-label\": \"COMERCIAL DESCRIPTION\"}):\n",
    "    product_list.add(prod.getText(strip=True))\n",
    "print(product_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lf international\n",
      "Pakistan\n",
      "{'FRESH POTATOES'}\n"
     ]
    }
   ],
   "source": [
    "# https://www.seair.co.in/lf-international-exporters-in-pakistan\n",
    "print(soup.find('h1').text.strip())\n",
    "print(soup.find('h2', class_=\"h6 mt-3 mb-3\").getText(strip=True).replace(\"Exporter in \", ''))\n",
    "\n",
    "product_list = set()\n",
    "for prod in soup.find_all('td', attrs={\"data-lable\": \"Item Description\"}):\n",
    "    product_list.add(prod.getText(strip=True))\n",
    "print(product_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIZA INTERNATIONAL EXPORT\n",
      "India\n",
      "['rmg 80 % nylon / 20 % spandex knitted babies swimsuit  lining 90 % poly 10 % spandex knitted', 'mmf polyester/knitted rmg. baba suit twopcs set', 'mmf polyester/knitted rmg. baba suit twopcs set', 'polyester x knitted kids rmg with termalcoating', 'main 100%polyester & sleeves 100%cottonknitted babies garments (cardigans)']\n"
     ]
    }
   ],
   "source": [
    "#https://www.seair.co.in/indian-trader/ut-corp.aspx\n",
    "ul = soup.find(\"ol\", class_=\"breadcrumb\")\n",
    "li_list = ul.find_all(\"li\")\n",
    "\n",
    "print(li_list[-1].text)\n",
    "title = soup.find('h1').text.strip()\n",
    "import re\n",
    "match = re.search(r'Trader in (.*?),', title)\n",
    "if match:\n",
    "    print(match.group(1))\n",
    "product_list = set()\n",
    "for prod in soup.find_all('td', attrs={\"data-label\": \"Item-Description\"}):\n",
    "    product_list.add(prod.text.strip())\n",
    "print(product_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COBOT CORP\n",
      "Importer in USA\n",
      "C O WEIR MINERALS LINATEX - SLC RECEIVING DOCK 3459 SOUTH 700 WEST SALT LAKE CITY UT 84119 USA ,United States\n",
      "COMPOUNDED RUBBER, UNVULCANIZED, COMPOUND WITH CARBON BLACK OR SILICA TARIFF CODE : 4005-10-0000 PO NUMBER:P000351-01 WEI WEIGHT:3,953.40 KG\n"
     ]
    }
   ],
   "source": [
    "## 'https://www.seair.co.in/us-importers/cobot-corp.aspx'\n",
    "ul = soup.find(\"ul\", class_=\"inner_breadcrumb\")\n",
    "li_list = ul.find_all(\"li\")\n",
    "print(li_list[-1].text)\n",
    "print(soup.find('h2', class_='h6 mt-3 mb-3').text.strip())\n",
    "print(soup.find('h5', class_=\"mt-3\").text.strip())\n",
    "\n",
    "sample_div = soup.find('div', class_=\"table-responsive table_side mt-4\")\n",
    "td = sample_div.find('td', text=\"Details\")\n",
    "if td:\n",
    "    td_list = td.findParent().find_all('td')\n",
    "    if len(td_list) >= 2:\n",
    "        print(td_list[1].text.strip())\n",
    "#soup.find('span', attrs={\"itemprop\": \"name\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://importkey.com/i/link-global-food-inc'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "    \n",
    "}\n",
    "page_response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "page_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINK GLOBAL FOOD INC\n",
      "165 KONRAD CRESCENT, MARKHAM, ON L3 R 9T9 .\n",
      "MORE ADDRESSES.....MORE ADDRESSES.....\n",
      "{'SEASONED & ROASTED SEAWEED KOREAN SAUCE', 'FOOD STUFF CITRON TEA SEASONED & ROASTED SEAW .', 'TOPOKKI'}\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h1').text.strip())\n",
    "print(soup.find('p', class_=\"companylocation\").getText(strip=True))\n",
    "li_list = soup.find_all('li', class_=\"dwnnor\")\n",
    "\n",
    "item_list = set()\n",
    "for li in li_list:\n",
    "    for detail in li.find_all('div', class_=\"dwncol ship dwn4\"):\n",
    "        item_list.add(detail.getText(strip=True))\n",
    "\n",
    "print(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(site:www.importgenius.com'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = '(site:www.importgenius.com OR site:www.importgenius.co.kr) Montana Milling Inc'\n",
    "data_list = data.split()\n",
    "data_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['panjiva',\n",
       " 'exportgenius',\n",
       " 'importgenius',\n",
       " 'importgenius',\n",
       " 'exportgenius',\n",
       " 'importkey',\n",
       " 'seair']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import re\n",
    "\n",
    "# URL 리스트\n",
    "urls = [\n",
    "    \"site:importkey.com\",\n",
    "    \"(site:www.seair.co.in\"\n",
    "]\n",
    "\n",
    "# URL에서 도메인 이름을 추출하는 함수\n",
    "def extract_domain(url):\n",
    "    # URL이 http:// 또는 https://로 시작하지 않으면 추가\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        url = \"http://\" + url\n",
    "    \n",
    "    # URL 파싱\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc\n",
    "    \n",
    "    # www. 제거\n",
    "    domain = domain.replace(\"www.\", \"\")\n",
    "    \n",
    "    # 도메인 이름 추출\n",
    "    match = re.search(r\"([a-zA-Z0-9.-]+)\\.[a-zA-Z.]{2,5}\", domain)\n",
    "    if match:\n",
    "        # 첫 번째 매치 그룹을 .으로 분리하고 첫 부분 반환\n",
    "        return match.group(1).split('.')[0]\n",
    "    return None\n",
    "\n",
    "# 각 URL에서 도메인 이름 추출\n",
    "domain_names = [extract_domain(url) for url in urls]\n",
    "domain_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
