{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\n",
    "#'http://www.kimtex.com',\n",
    "'http://swamyweb.com',\n",
    "\n",
    "'http://www.kurashiki.com.br',\n",
    "# 'http://www.unitexbd.com',\n",
    "\n",
    "# 'http://www.beddinghouse.com',\n",
    "#'http://www.nineandco.com',\n",
    "# 'http://www.carcemal.pt',\n",
    "# 'http://www.silsa.pt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoonhae/.pyenv/versions/3.8.12/envs/crawling/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.vertexai.VertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "from langchain.llms.vertexai import VertexAI\n",
    "\n",
    "PROJECT_ID = \"grainscanner\"  # @param {type:\"string\"}\n",
    "REGION = \"asia-northeast3\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# Text model instance integrated with langChain\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-pro\",#\"text-bison\",\n",
    "    max_output_tokens=4096,\n",
    "    temperature=0.4,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "import json\n",
    "\n",
    "RETRY_COUNT = 3\n",
    "\n",
    "def get_string_item(dict_item, key):\n",
    "    if isinstance(dict_item, dict):\n",
    "        value = dict_item.get(key, '')\n",
    "        if not value:\n",
    "            return \"\"\n",
    "        \n",
    "        while isinstance(value, list) and value:\n",
    "            value = value[0]\n",
    "        return value\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def get_list_item(dict_item, key):\n",
    "    if isinstance(dict_item, dict):\n",
    "        value = dict_item.get(key, [])\n",
    "        return value\n",
    "    elif isinstance(dict_item, list):\n",
    "        return dict_item\n",
    "    \n",
    "    return []\n",
    "\n",
    "\n",
    "def get_url_list_with_llm(llm, a_tag_list):\n",
    "    json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "    filter_template = \"\"\"\n",
    "        당신은 유능하고 경험 많은 웹 제작자입니다.\n",
    "        다음 global 회사 홈페이지에 태그된  a태그 리스트를 보고 \n",
    "        회사에 contact 할 수 있는 정보를 담은 a태그와 \n",
    "        취급 product를 설명하는 a태그만 골라서 href attribute를 추출해주세요.\n",
    "        판단은 엄격하게 진행해주세요.\n",
    "\n",
    "        Format instructions:\n",
    "        [\"href attribute\", \"href attribute\"]\n",
    "\n",
    "        -----------------------\n",
    "        content :\n",
    "        {a_tag_list}\n",
    "    \"\"\"\n",
    "\n",
    "    filter_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"a_tag_list\"], \n",
    "        template=filter_template, \n",
    "        output_parser=json_parser,\n",
    "        partial_variables={\n",
    "            \"format_instructions\": json_parser.get_format_instructions()\n",
    "        }\n",
    "    )\n",
    "\n",
    "    chain = filter_prompt_template|llm|json_parser\n",
    "\n",
    "    retry_count = 0\n",
    "    last_error = None\n",
    "    result_additional_filter_json = None\n",
    "    while retry_count < RETRY_COUNT:\n",
    "        try:\n",
    "            result_additional_filter_json = chain.invoke({\"a_tag_list\": a_tag_list})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'    ** retry[{retry_count+1}] - ', e)\n",
    "            last_error = str(e)\n",
    "        retry_count += 1\n",
    "\n",
    "    if result_additional_filter_json:\n",
    "        print('   ', result_additional_filter_json)\n",
    "        return result_additional_filter_json\n",
    "    else:\n",
    "        return {'error': last_error}\n",
    "\n",
    "\n",
    "def get_firm_info_with_llm(llm, page_text):\n",
    "    json_parser = SimpleJsonOutputParser()\n",
    "    html_template = \"\"\"\n",
    "        당신은 유능한 global html parsor 입니다. \n",
    "        주어진 html 은 global 회사의 웹페이지입니다. \n",
    "        회사에 contact 할 수 있는 email, phone, fax, address 을 추출해주세요. \n",
    "        더불어 취급 products가 있다면 핵심 물품만 keyword list로 추출해주세요.\n",
    "        \n",
    "        결과는 json 으로 구성해서 전달해주세요.\n",
    "\n",
    "        Format instructions:\n",
    "        {format_instructions}\n",
    "\n",
    "        ------------\n",
    "        content:\n",
    "        {page_text}\n",
    "    \"\"\"\n",
    "\n",
    "    html_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"page_text\"], \n",
    "        template=html_template, \n",
    "        output_parser=json_parser,\n",
    "        partial_variables={\n",
    "            \"format_instructions\": json_parser.get_format_instructions()# + \"\\n\" + \"json key are (email, phone, address, items)\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    html_chain = html_prompt_template | llm | json_parser\n",
    "    retry_count = 0\n",
    "    result_html_json = None\n",
    "    last_error = None\n",
    "    while retry_count < RETRY_COUNT:\n",
    "        try :\n",
    "            result_html_json = html_chain.invoke({\"page_text\": page_text})\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'    ** retry[{retry_count+1}] - ', e)\n",
    "            last_error = str(e)\n",
    "        retry_count += 1\n",
    "\n",
    "    if result_html_json:\n",
    "        print('   ', '\\n    '.join(json.dumps(result_html_json, indent=4).split('\\n')))\n",
    "        return result_html_json\n",
    "    else:\n",
    "        return {'error': last_error}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import aiplatform\n",
    "import time\n",
    "\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "requests.adapters.DEFAULT_POOLSIZE = 100\n",
    "retries = Retry(total=20)\n",
    "# 세션을 생성하고 ConnectionPool 크기를 설정\n",
    "session = requests.Session()\n",
    "session.mount('https://', requests.adapters.HTTPAdapter(pool_connections=100, pool_maxsize=100, max_retries=retries))\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "get_domain = lambda url: urlparse(url).netloc.replace('www.', '')\n",
    "\n",
    "def change_protocol(url):\n",
    "    # URL 파싱\n",
    "    parsed_url = urlparse(url)\n",
    "    # 프로토콜 추출\n",
    "    protocol = parsed_url.scheme\n",
    "    if protocol == 'http':\n",
    "        return parsed_url._replace(scheme='https').geturl()\n",
    "    elif protocol == 'https':\n",
    "        return parsed_url._replace(scheme='http').geturl()\n",
    "\n",
    "    return url\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "def extract_content(url, is_recursive=False):\n",
    "    # 페이지 콘텐츠를 가져옵니다.\n",
    "    time.sleep(0.5)\n",
    "    response = requests.get(url, headers=headers, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return response.status_code, soup\n",
    "    elif response.status_code == 403:\n",
    "        if not is_recursive:\n",
    "            print(f'    ** page 조회 - retry')\n",
    "            return extract_content(change_protocol(url), is_recursive=True)\n",
    "    return response.status_code, None\n",
    "\n",
    "\n",
    "def run(main_url):\n",
    "    print(f'** [main page] 조회 - {main_url}')\n",
    "    status, soup = extract_content(main_url)\n",
    "\n",
    "    result = []\n",
    "    if status == 200:\n",
    "        print(f'  ** [llm] contact 정보 & products 추출')\n",
    "        firm_info = {'homepage': main_url,\n",
    "                     'extract_url': main_url}\n",
    "        try :\n",
    "            info = get_firm_info_with_llm(llm, soup.get_text())\n",
    "            if info:\n",
    "                firm_info.update(info)\n",
    "        except Exception as e:\n",
    "            firm_info['error'] = str(e)\n",
    "        result.append(firm_info)\n",
    "\n",
    "        print(f'  ** a tag 추출')\n",
    "        a_list = soup.find_all('a', href=True)\n",
    "        \n",
    "        main_domain = get_domain(main_url)\n",
    "        distinct_a_list = {}\n",
    "        for link in a_list:\n",
    "            if get_domain(link.get('href')).startswith(main_domain):\n",
    "                distinct_a_list[link.get('href').strip('/')] = link\n",
    "        \n",
    "        if distinct_a_list:\n",
    "            print(f'  ** [llm] 회사 정보와 관련있는 a tag 선별')\n",
    "            page_list = get_url_list_with_llm(llm, [distinct_a_list.values()])\n",
    "        \n",
    "            for sub_url in page_list:\n",
    "                print(f'  ** [sub page] 조회 - {sub_url}')\n",
    "                sub_status, sub_soup = extract_content(sub_url)\n",
    "                if sub_status == 200:\n",
    "                    print(f'  ** [llm] contact 정보 & products 추출')\n",
    "                    sub_firm_info = {'homepage': main_url,\n",
    "                                    'extract_url': sub_url}\n",
    "                    try :\n",
    "                        info = get_firm_info_with_llm(llm, sub_soup.get_text())\n",
    "                        if info:\n",
    "                            sub_firm_info.update(info)\n",
    "                    except Exception as e:\n",
    "                        sub_firm_info['error'] = str(e)\n",
    "                    result.append(sub_firm_info)\n",
    "                else:\n",
    "                    print(f'    [{sub_status}] : 조회 실패')\n",
    "        else:\n",
    "            print(f'    [empty]')\n",
    "    else:\n",
    "        print(f'    [{status}] : 조회 실패')\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** [main page] 조회 - http://swamyweb.com\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"info@swamycottonmill.co.in\",\n",
      "            \"phone\": \"(91) 421 2344042\",\n",
      "            \"fax\": \"(91) 421 2345750\",\n",
      "            \"address\": \"S.F.No.407/2, Peerchangadu, Tirupur-641663.\"\n",
      "        },\n",
      "        \"products\": [\n",
      "            \"Cotton\",\n",
      "            \"Viscose\",\n",
      "            \"Linen\",\n",
      "            \"Woven Fabrics\"\n",
      "        ]\n",
      "    }\n",
      "  ** a tag 추출\n",
      "  ** [llm] 회사 정보와 관련있는 a tag 선별\n",
      "    ['https://swamyweb.com/contact-us/', 'http://swamyweb.com/demo/contact-us/']\n",
      "  ** [sub page] 조회 - https://swamyweb.com/contact-us/\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"info@swamycottonmill.co.in\",\n",
      "            \"phone\": \"+ 91 421 2344042\",\n",
      "            \"fax\": \"+ 91 421 2345750\",\n",
      "            \"address\": \"S.F.No.407/2,\\nPeerchangadu,\\nMangalam,\\nTirupur \\u2013 641663.\"\n",
      "        },\n",
      "        \"products\": []\n",
      "    }\n",
      "  ** [sub page] 조회 - http://swamyweb.com/demo/contact-us/\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"info@swamycottonmill.co.in\",\n",
      "            \"phone\": \"+ 91 421 2344042\",\n",
      "            \"fax\": \"+ 91 421 2345750\",\n",
      "            \"address\": \"S.F.No.407/2,\\nPeerchangadu,\\nMangalam,\\nTirupur \\u2013 641663.\"\n",
      "        },\n",
      "        \"products\": []\n",
      "    }\n",
      "** [main page] 조회 - http://www.kurashiki.com.br\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"vendas@kurashiki.com.br\",\n",
      "            \"phone\": \"55 (11) 3284-7644\",\n",
      "            \"fax\": null,\n",
      "            \"address\": \"Av. Paulista, 542 - Bela Vista - S\\u00e3o Paulo/SP\"\n",
      "        },\n",
      "        \"products\": [\n",
      "            \"Fio Penteado\",\n",
      "            \"Fio Cardado\"\n",
      "        ]\n",
      "    }\n",
      "  ** a tag 추출\n",
      "  ** [llm] 회사 정보와 관련있는 a tag 선별\n",
      "    ['https://www.kurashiki.com.br/contato/', 'http://www.kurashiki.com.br/produtos']\n",
      "  ** [sub page] 조회 - https://www.kurashiki.com.br/contato/\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"vendas@kurashiki.com.br\",\n",
      "            \"phone\": \"55 (11) 3284-7644\",\n",
      "            \"fax\": null,\n",
      "            \"address\": \"Av. Paulista, 542 - Bela Vista - S\\u00e3o Paulo/SP\"\n",
      "        },\n",
      "        \"products\": []\n",
      "    }\n",
      "  ** [sub page] 조회 - http://www.kurashiki.com.br/produtos\n",
      "  ** [llm] contact 정보 & products 추출\n",
      "    {\n",
      "        \"contact\": {\n",
      "            \"email\": \"vendas@kurashiki.com.br\",\n",
      "            \"phone\": \"55 (11) 3284-7644\",\n",
      "            \"fax\": null,\n",
      "            \"address\": \"Av. Paulista, 542 - Bela Vista - S\\u00e3o Paulo/SP\"\n",
      "        },\n",
      "        \"products\": [\n",
      "            \"Fio Penteado\",\n",
      "            \"Fio Cardado\"\n",
      "        ]\n",
      "    }\n",
      "[finish!]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for url in url_list:\n",
    "    sub_result = run(url)\n",
    "    if sub_result:\n",
    "        result.extend(sub_result)\n",
    "print('[finish!]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 제공된 JSON 데이터\n",
    "json_data = result\n",
    "normalized_df = pd.json_normalize(json_data)\n",
    "\n",
    "target_column_list = ['homepage', 'extract_url', 'company_name', 'mail', 'phone', 'address', 'fax', 'products', 'error']\n",
    "total_column_list = list(normalized_df.columns)\n",
    "\n",
    "merged_df = pd.DataFrame(columns=target_column_list)\n",
    "\n",
    "for target_col in target_column_list:\n",
    "    related_cols = [col for col in total_column_list if target_col in col]\n",
    "\n",
    "    def merge_row(row):\n",
    "        merged_data = []\n",
    "        for item in row.dropna():\n",
    "            if isinstance(item, dict):\n",
    "                merged_data.append(json.dumps(item, ensure_ascii=False))\n",
    "            elif isinstance(item, list):\n",
    "                merged_data.extend([str(x) for x in item])\n",
    "            elif not pd.isnull(item):\n",
    "                merged_data.append(item)\n",
    "        if merged_data:\n",
    "            return ';\\n'.join(merged_data)\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    if related_cols:\n",
    "        merged_df[target_col] = normalized_df[related_cols].apply(merge_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = './output/beautifulsoup_sample.csv'\n",
    "merged_df.to_csv(file_path, index=False)\n",
    "\n",
    "# Numbers 애플리케이션으로 CSV 파일 열기\n",
    "os.system(f'open -a Numbers {file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
